{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMICZw/cURjIYLa0p9JeFlN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Face Blurring for Privacy:**\n","## *A Video Anonymization Tool*\n"],"metadata":{"id":"nIiPSBnGQiFh"}},{"cell_type":"markdown","source":["**Note to Users:**\n","\n","For optimal performance and faster rendering times, it is recommended to use this tool with Google Colab. You can easily run the provided Colab notebook by following these steps:\n","\n","1. Open Google Colab: [Google Colab](https://colab.research.google.com/)\n","\n","2. Create a New Notebook.\n","\n","3. Copy and Paste the provided code into the notebook.\n","\n","4. Mount your Google Drive using the code cell provided.\n","\n","5. Upload your video file to your Google Drive and adjust the file paths in the script accordingly.\n","\n","6. Run the cells in the notebook to execute the face-blurring script.\n","\n","By using Google Colab, you'll benefit from the cloud-based computation, significantly reducing render times.\n"],"metadata":{"id":"6Bjzazm_RGVv"}},{"cell_type":"markdown","source":["Mounting Google Drive in Colab"],"metadata":{"id":"T7xSKhNxQsDe"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NTP410SsQt26","executionInfo":{"status":"ok","timestamp":1700745625157,"user_tz":-240,"elapsed":3396,"user":{"displayName":"Akif Khan","userId":"01308960506171406145"}},"outputId":"bbe0e3a2-3770-4311-9dff-b542619d22f3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["Installing Mediapipe Library"],"metadata":{"id":"xXMQeUL9RPla"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sot7M_-OQg7T","executionInfo":{"status":"ok","timestamp":1700745904199,"user_tz":-240,"elapsed":10869,"user":{"displayName":"Akif Khan","userId":"01308960506171406145"}},"outputId":"b2e9223b-77db-4797-c301-7a32960e6e96"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: Mediapipe in /usr/local/lib/python3.10/dist-packages (0.10.8)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from Mediapipe) (1.4.0)\n","Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from Mediapipe) (23.1.0)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from Mediapipe) (23.5.26)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from Mediapipe) (3.7.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from Mediapipe) (1.23.5)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from Mediapipe) (4.8.0.76)\n","Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.10/dist-packages (from Mediapipe) (3.20.3)\n","Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from Mediapipe) (0.4.6)\n","Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->Mediapipe) (1.16.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->Mediapipe) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->Mediapipe) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->Mediapipe) (4.44.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->Mediapipe) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->Mediapipe) (23.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->Mediapipe) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->Mediapipe) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->Mediapipe) (2.8.2)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->Mediapipe) (2.21)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->Mediapipe) (1.16.0)\n"]}],"source":["!pip install Mediapipe"]},{"cell_type":"markdown","source":["Face Blurring Algorithm"],"metadata":{"id":"zPzq3Y4mRpNf"}},{"cell_type":"code","source":["import cv2\n","import mediapipe as mp\n","from moviepy.editor import VideoFileClip\n","import os\n","import numpy as np\n","\n","# Load the video from your drive\n","video_path = \"/content/drive/MyDrive/Project/sample.mp4\"  # <----- Input your file here\n","final_output_path = '/content/drive/MyDrive/Project/result.mp4'  # <----- Output file\n","\n","# Get the frames per second (fps) of the input video\n","video_capture = cv2.VideoCapture(video_path)\n","fps = video_capture.get(cv2.CAP_PROP_FPS)\n","\n","# Get video width and height\n","width = int(video_capture.get(3))\n","height = int(video_capture.get(4))\n","\n","# Initialize a list to store processed frames\n","processed_frames = []\n","\n","# Initialize Mediapipe FaceMesh\n","mp_face_mesh = mp.solutions.face_mesh\n","face_mesh = mp_face_mesh.FaceMesh()\n","\n","while True:\n","    # Read each frame from the video\n","    ret, frame = video_capture.read()\n","    if not ret:\n","        break\n","\n","    # Resize the frame to reduce processing time\n","    frame = cv2.resize(frame, (width, height))\n","\n","    # Convert the frame to RGB\n","    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","\n","    # Process the frame with Mediapipe FaceMesh\n","    result = face_mesh.process(rgb_frame)\n","\n","    # If faces are detected, apply stronger mosaic blur\n","    if result.multi_face_landmarks:\n","        for face_landmarks in result.multi_face_landmarks:\n","            landmarks = np.array([(landmark.x * width, landmark.y * height) for landmark in face_landmarks.landmark])\n","\n","            # Convert the landmarks to a list of tuples\n","            landmarks_list = [(int(landmark[0]), int(landmark[1])) for landmark in landmarks]\n","\n","            # Convert landmarks_list to NumPy array\n","            landmarks_np = np.array(landmarks_list)\n","\n","            # Expand the region around the face landmarks to capture the entire head\n","            x, y, w, h = cv2.boundingRect(landmarks_np)\n","            expanded_x = max(0, x - int(0.2 * w))\n","            expanded_y = max(0, y - int(0.2 * h))\n","            expanded_w = min(width, x + w + int(0.2 * w)) - expanded_x\n","            expanded_h = min(height, y + h + int(0.2 * h)) - expanded_y\n","\n","            # Extract the expanded face region\n","            sub_face = frame[expanded_y:expanded_y + expanded_h, expanded_x:expanded_x + expanded_w]\n","\n","            # Apply stronger mosaic blur directly\n","            sub_face = cv2.resize(sub_face, (10, 10),\n","                                  interpolation=cv2.INTER_NEAREST)\n","            sub_face = cv2.resize(sub_face, (expanded_w, expanded_h),\n","                                  interpolation=cv2.INTER_NEAREST)\n","            frame[expanded_y:expanded_y + expanded_h, expanded_x:expanded_x + expanded_w] = sub_face\n","\n","    # Append the processed frame to the list\n","    processed_frames.append(frame)\n","\n","# Release the video capture object\n","video_capture.release()\n","\n","# Write the processed frames to a new video file\n","output_path = '/content/drive/MyDrive/Project/temp_without_audio.mp4'\n","out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n","\n","for frame in processed_frames:\n","    out.write(frame)\n","\n","# Release the video writer object\n","out.release()\n","\n","original_clip = VideoFileClip(video_path)\n","processed_clip = VideoFileClip(output_path)\n","final_clip = processed_clip.set_audio(original_clip.audio)\n","\n","# Write the final video with audio\n","final_clip.write_videofile(final_output_path, codec='libx264', audio_codec='aac',\n","                           fps=original_clip.fps, preset=\"ultrafast\")\n","\n","# Close the video clips\n","original_clip.close()\n","processed_clip.close()\n","\n","# Delete the temp data files\n","os.remove(output_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zpseu1niRszP","executionInfo":{"status":"ok","timestamp":1700745750580,"user_tz":-240,"elapsed":118314,"user":{"displayName":"Akif Khan","userId":"01308960506171406145"}},"outputId":"dbfb4f00-4a28-4df6-81c4-f4bf1a264196"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Moviepy - Building video /content/drive/MyDrive/Project/result.mp4.\n","MoviePy - Writing audio in resultTEMP_MPY_wvf_snd.mp4\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["MoviePy - Done.\n","Moviepy - Writing video /content/drive/MyDrive/Project/result.mp4\n","\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Moviepy - Done !\n","Moviepy - video ready /content/drive/MyDrive/Project/result.mp4\n"]}]}]}